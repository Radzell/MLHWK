{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import copy\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 567
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tanh(x):\n",
      "    return np.tanh(x)\n",
      "\n",
      "def tanh_deriv(x):\n",
      "    return 1.0 - x**2\n",
      "\n",
      "def logistic(x):\n",
      "    return x\n",
      "\n",
      "def logistic_derivative(x):\n",
      "    return 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 568
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class NeuralNetwork:\n",
      "    \n",
      "    def __init__(self, layers,w=None,activation='tanh'):\n",
      "        \"\"\"\n",
      "        :param layers: A list containing the number of units in each layer. Should be at least two values\n",
      "        :param activation: The activation function to be used. Can be \"logistic\" or \"tanh\"\n",
      "        \"\"\"\n",
      "        self.ident = activation\n",
      "        if activation == 'ident':\n",
      "            self.activation = logistic\n",
      "            self.activation_deriv = logistic_derivative\n",
      "        elif activation == 'tanh':\n",
      "            self.activation = tanh\n",
      "            self.activation_deriv = tanh_deriv\n",
      "        if(w is None):\n",
      "            self.weights = []\n",
      "            for i in range(1, len(layers) - 1):\n",
      "                self.weights.append((2*np.random.random((layers[i - 1] + 1, layers[i] + 1))-1)*0.25)\n",
      "            self.weights.append((2*np.random.random((layers[i] + 1, layers[i + 1]))-1)*0.25)\n",
      "        else:\n",
      "            self.weights = w\n",
      "        self.L = len(self.weights)\n",
      "            \n",
      "    def fitBeta(self, X, y):\n",
      "        Ein = 0\n",
      "        N = len(X)\n",
      "        Gl = copy.deepcopy(self.weights)        \n",
      "        for layer in range(len(Gl)):\n",
      "            for i in range(len(Gl[layer])):\n",
      "                for j in range(len(Gl[layer][i])):\n",
      "                    Gl[layer][i][j] = 0\n",
      "        for i in range(len(X)):\n",
      "            x = X[i]\n",
      "            xl,sl=self.forward_prop(x)\n",
      "            deltas = self.back_prop(xl,sl) \n",
      "            Ein =Ein+ (1.0/(4*N))*(xl[-1]-y[i])**2\n",
      "            for l in range(self.L):\n",
      "                d = np.atleast_2d(deltas[l])\n",
      "                GlXn = np.dot(2*(xl[-1][0]-y[i]),np.dot(xl[l],d.T))\n",
      "                Gl[l]=Gl[l]+(1.0/N)*(GlXn/N)\n",
      "        print 'Ein {0}'.format(Ein)\n",
      "        print 'Gl {0}'.format(Gl)\n",
      "    def back_prop(self,xl,sl):\n",
      "        deltas = [None]*self.L\n",
      "        deltas[self.L-1]=self.activation_deriv(xl[-1])\n",
      "        for i in reversed(range(self.L-1)):\n",
      "            w=np.array(self.weights[i+1][1:])\n",
      "            if not self.ident=='ident':\n",
      "                d=np.atleast_2d(deltas[i+1])\n",
      "                deltas[i]=np.dot(np.diagflat(self.activation_deriv(xl[i+1][1:])),np.atleast_2d(w.dot(d)))\n",
      "            else:\n",
      "                deltas[i]=w.dot(deltas[i+1])\n",
      "        return deltas\n",
      "    def forward_prop(self,X):\n",
      "        #adding bias to X\n",
      "        temp = np.array(X)\n",
      "        xl = [temp]\n",
      "        sl=[]\n",
      "        for i in range(self.L):\n",
      "            w=np.array(self.weights[i])\n",
      "            x=xl[i]\n",
      "            sl.append(w.T.dot(x))\n",
      "            temp = sl[-1]\n",
      "            temp=self.activation(temp)\n",
      "            temp=np.insert(temp,0,1,axis=0)\n",
      "            xl.append(temp)\n",
      "        xl[-1]=np.delete(xl[-1],0)\n",
      "        return xl,sl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 696
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w=[\n",
      "                [\n",
      "                        [0.1, 0.2], \n",
      "                        [0.3, 0.4],\n",
      "                ],\n",
      "                [\n",
      "                        [0.2],\n",
      "                        [1],\n",
      "                        [-3]\n",
      "                ],\n",
      "                [\n",
      "                        [1],\n",
      "                        [2]\n",
      "                ]\n",
      "]\n",
      "X = [\n",
      "                 [       \n",
      "                         [1],\n",
      "                         [2]\n",
      "                 ]\n",
      "     \n",
      "     ]\n",
      "y= [1]\n",
      "nn = NeuralNetwork([2,2,1],w=w ,activation='tanh')\n",
      "nn.fitBeta(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Ein [ 0.69369029]\n",
        "Gl [array([[-0.44083838,  0.87503983],\n",
        "       [-0.88167675,  1.75007965]]), array([[-0.69451848],\n",
        "       [-0.41974459],\n",
        "       [-0.52894122]]), array([[-1.85486437],\n",
        "       [ 1.67224491]])]\n"
       ]
      }
     ],
     "prompt_number": 697
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w=[\n",
      "                [\n",
      "                        [0.25, 0.25],\n",
      "                        [0.25, 0.25]\n",
      "                ],\n",
      "                [\n",
      "                        [0.25],\n",
      "                        [0.25],\n",
      "                        [0.25]\n",
      "                ]\n",
      "]\n",
      "X = [\n",
      "                 [       \n",
      "                         [1],\n",
      "                         [1]\n",
      "                 ]\n",
      "     \n",
      "     ]\n",
      "y= [1]\n",
      "nn = NeuralNetwork([2,2,1],w=w ,activation='tanh')\n",
      "nn.fitBeta(X,y)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Ein [ 0.07642709]\n",
        "Gl [array([[-0.17395745, -0.17395745],\n",
        "       [-0.17395745, -0.17395745]]), array([[-0.88477567],\n",
        "       [-0.40887002],\n",
        "       [-0.40887002]])]\n"
       ]
      }
     ],
     "prompt_number": 698
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w=[\n",
      "                [\n",
      "                        [0.25, 0.25],\n",
      "                        [0.25, 0.25]\n",
      "                ],\n",
      "                [\n",
      "                        [0.25],\n",
      "                        [0.25],\n",
      "                        [0.25]\n",
      "                ]\n",
      "]\n",
      "X = [\n",
      "                 [       \n",
      "                         [1],\n",
      "                         [1]\n",
      "                 ]\n",
      "     \n",
      "     ]\n",
      "y= [1]\n",
      "nn = NeuralNetwork([2,2,1],w=w ,activation='ident')\n",
      "nn.fitBeta(X,y)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[ 0.30570837]\n",
      "[array([[-0.17395745, -0.17395745],\n",
      "       [-0.17395745, -0.17395745]]), array([[-0.88477567],\n",
      "       [-0.40887002],\n",
      "       [-0.40887002]])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 695,
       "text": [
        "[array([[-0.17395745, -0.17395745],\n",
        "       [-0.17395745, -0.17395745]]),\n",
        " array([[-0.88477567],\n",
        "       [-0.40887002],\n",
        "       [-0.40887002]])]"
       ]
      }
     ],
     "prompt_number": 695
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 572
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 572
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 572
    }
   ],
   "metadata": {}
  }
 ]
}